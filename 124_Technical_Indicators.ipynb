{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "url = 'https://anaconda.org/conda-forge/libta-lib/0.4.0/download/linux-64/libta-lib-0.4.0-h166bdaf_1.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/lib/x86_64-linux-gnu/ lib --strip-components=1\n",
        "url = 'https://anaconda.org/conda-forge/ta-lib/0.4.19/download/linux-64/ta-lib-0.4.19-py310hde88566_4.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/local/lib/python3.10/dist-packages/ lib/python3.10/site-packages/talib --strip-components=3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XldYXARb8OK",
        "outputId": "a59c4f95-0e47-4586-fb67-1bf265c00b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4457    0  4457    0     0   5185      0 --:--:-- --:--:-- --:--:--  5182\n",
            "100  517k  100  517k    0     0   192k      0  0:00:02  0:00:02 --:--:--  323k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4497    0  4497    0     0   3901      0 --:--:--  0:00:01 --:--:--  3903\n",
            "100  392k  100  392k    0     0   141k      0  0:00:02  0:00:02 --:--:--  271k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1h6wNzTbdWU",
        "outputId": "972bb950-f156-4c70-8201-844e99aeb1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[indicator] = result\n",
            "<ipython-input-2-1a529d3dbffc>:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['HT DCPERIOD'] = talib.HT_DCPERIOD(df['Close'])\n",
            "<ipython-input-2-1a529d3dbffc>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['HT DCPHASE'] = talib.HT_DCPHASE(df['Close'])\n",
            "<ipython-input-2-1a529d3dbffc>:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['TRENDMODE'] = talib.HT_TRENDMODE(df['Close'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278.4970763181784\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import talib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/DATA2.csv')\n",
        "#df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Define categories\n",
        "\n",
        "overlap_studies = ['BBAND WIDTH', 'BBAND UPPER SIGNAL', 'BBAND LOWER SIGNAL', 'DEMA', 'EMA', 'HTRENDLINE', 'KMAM', 'MIDPOINT', 'MIDPRICE', 'SAR', 'SAREXT', 'SMA3', 'SMA5', 'SMA10', 'SMA20', 'TEMA', 'TRIMA', 'WMA']\n",
        "momentum_indicators = ['ADX14', 'ADX20', 'ADXR', 'APO', 'AROONOSC', 'BOP', 'CCI3', 'CCI5', 'CCI10', 'CCI14', 'CMO', 'DX', 'MACD', 'MACDSIGNAL', 'MACDHIST', 'MINUS_DI', 'MINUS_DM', 'MOM1', 'MOM3', 'MOM5', 'MOM10', 'PLUS_DI', 'PLUS_DM', 'PPO', 'ROC', 'ROCP', 'ROCR', 'ROCR100', 'RSI5', 'RSI10', 'RSI14', 'SLOWK', 'SLOWD', 'FASTK', 'FASTD', 'TRIX','ULTOSC', 'WILLR']\n",
        "volatility_indicators = ['ATR', 'NATR', 'TRANGE']\n",
        "pattern_recognition = ['CDL2CROWS', 'CDL3BLACKCROWS', 'CDL3INSIDE', 'CDL3LINESTRIKE', 'CDL3OUTSIDE', 'CDL3STARSINSOUTH', 'CDL3WHITESOLDIERS', 'CDLABANDONEDBABY', 'CDLADVANCEBLOCK', 'CDLBELTHOLD', 'CDLBREAKAWAY', 'CDLCLOSINGMARUBOZU', 'CDLCONCEALBABYSWALL', 'CDLCOUNTERATTACK', 'CDLDARKCLOUDCOVER', 'CDLDOJI', 'CDLDOJISTAR', 'CDLDRAGONFLYDOJI', 'CDLENGULFING', 'CDLEVENINGDOJISTAR', 'CDLEVENINGSTAR', 'CDLGAPSIDESIDEWHITE', 'CDLGRAVESTONEDOJI', 'CDLHAMMER', 'CDLHANGINGMAN', 'CDLHARAMI', 'CDLHARAMICROSS', 'CDLHIGHWAVE', 'CDLHIKKAKE', 'CDLHIKKAKEMOD', 'CDLHOMINGPIGEON', 'CDLIDENTICAL3CROWS', 'CDLINNECK', 'CDLINVERTEDHAMMER', 'CDLKICKING', 'CDLKICKINGBYLENGTH', 'CDLLADDERBOTTOM', 'CDLLONGLEGGEDDOJI', 'CDLLONGLINE', 'CDLMARUBOZU', 'CDLMATCHINGLOW', 'CDLMATHOLD', 'CDLMORNINGDOJISTAR', 'CDLMORNINGSTAR', 'CDLONNECK', 'CDLPIERCING', 'CDLRICKSHAWMAN', 'CDLRISEFALL3METHODS', 'CDLSEPARATINGLINES', 'CDLSHOOTINGSTAR', 'CDLSHORTLINE', 'CDLSPINNINGTOP', 'CDLSTALLEDPATTERN', 'CDLSTICKSANDWICH', 'CDLTAKURI', 'CDLTASUKIGAP', 'CDLTHRUSTING', 'CDLTRISTAR', 'CDLUNIQUE3RIVER', 'CDLUPSIDEGAP2CROWS', 'CDLXSIDEGAP3METHODS']\n",
        "cycle_indicators = ['HT DCPERIOD', 'HT DCPHASE', 'TRENDMODE']\n",
        "\n",
        "# Combine all indicators into one list\n",
        "all_indicators = overlap_studies + momentum_indicators + volatility_indicators + pattern_recognition + cycle_indicators\n",
        "\n",
        "# OVERLAP STUDIES\n",
        "\n",
        "# BBAND WIDTH\n",
        "upper_band, middle_band, lower_band = talib.BBANDS(df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
        "bband_width = (upper_band - lower_band) / middle_band\n",
        "upper_signal = (df['Close'] > upper_band).astype(int)\n",
        "lower_signal = (df['Close'] < lower_band).astype(int)\n",
        "df['BBAND WIDTH'] = bband_width\n",
        "df['BBAND UPPER SIGNAL'] = upper_signal\n",
        "df['BBAND LOWER SIGNAL'] = lower_signal\n",
        "\n",
        "# DEMA\n",
        "dema = talib.DEMA(df['Close'], timeperiod=30)\n",
        "df['DEMA'] = dema\n",
        "\n",
        "# EMA\n",
        "ema = talib.EMA(df['Close'], timeperiod=20)\n",
        "df['EMA'] = ema\n",
        "\n",
        "# H TRENDLINE\n",
        "ht_trendline = talib.HT_TRENDLINE(df['Close'])\n",
        "df['HTRENDLINE'] = ht_trendline\n",
        "\n",
        "# KMAM\n",
        "kmam = talib.KAMA(df['Close'], timeperiod=30)\n",
        "df['KMAM'] = kmam\n",
        "\n",
        "# MIDPOINT\n",
        "midpoint = talib.MIDPOINT(df['Close'], timeperiod=14)\n",
        "df['MIDPOINT'] = midpoint\n",
        "\n",
        "# MIDPRICE\n",
        "midprice = talib.MIDPRICE(df['High'], df['Low'], timeperiod=14)\n",
        "df['MIDPRICE'] = midprice\n",
        "\n",
        "# SAR\n",
        "sar = talib.SAR(df['High'], df['Low'], acceleration=0.02, maximum=0.2)\n",
        "df['SAR'] = sar\n",
        "\n",
        "# SAREXT\n",
        "sar_ext = talib.SAREXT(df['High'], df['Low'])\n",
        "df['SAREXT'] = sar_ext\n",
        "\n",
        "# SMA3, SMA5, SMA10, SMA20, TEMA, TRIMA AND WMA.\n",
        "\n",
        "sma3 = talib.SMA(df['Close'], timeperiod=3)\n",
        "sma5 = talib.SMA(df['Close'], timeperiod=5)\n",
        "sma10 = talib.SMA(df['Close'], timeperiod=10)\n",
        "sma20 = talib.SMA(df['Close'], timeperiod=20)\n",
        "tema = talib.TEMA(df['Close'], timeperiod=30)\n",
        "trima = talib.TRIMA(df['Close'], timeperiod=30)\n",
        "wma = talib.WMA(df['Close'], timeperiod=30)\n",
        "df['SMA3'] = sma3\n",
        "df['SMA5'] = sma5\n",
        "df['SMA10'] = sma10\n",
        "df['SMA20'] = sma20\n",
        "df['TEMA'] = tema\n",
        "df['TRIMA'] = trima\n",
        "df['WMA'] = wma\n",
        "\n",
        "# MOMENTUM INDICATORS\n",
        "\n",
        "# ADX14, ADX20, ADXR, APO, AROONOSC, BOP, CCI3, CCI5, CCI10, CCI14, CMO, DX, MACD, MACD SIGNAL and MACDHIST\n",
        "\n",
        "df['ADX14'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['ADX20'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=20)\n",
        "df['ADXR'] = talib.ADXR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['APO'] = talib.APO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
        "df['AROONOSC'] = talib.AROONOSC(df['High'], df['Low'], timeperiod=14)\n",
        "df['BOP'] = talib.BOP(df['Open'], df['High'], df['Low'], df['Close'])\n",
        "df['CCI3'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=3)\n",
        "df['CCI5'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=5)\n",
        "df['CCI10'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=10)\n",
        "df['CCI14'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['CMO'] = talib.CMO(df['Close'], timeperiod=14)\n",
        "df['DX'] = talib.DX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "macd, signal, hist = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "df['MACD'] = macd\n",
        "df['MACDSIGNAL'] = signal\n",
        "df['MACDHIST'] = hist\n",
        "\n",
        "# MINUS_DI, MINUS_DM, MOM1, MOM3, MOM5, MOM10, PLUS_DI, PLUS_DM, PPO, ROC, ROCP, ROCR, ROCR100, RSI5, RSI10, RSI14, SLOWK, SLOWD, FASTK, FASTD, TRIX, ULTOSC and WILLR\n",
        "\n",
        "df['MINUS_DI'] = talib.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['MINUS_DM'] = talib.MINUS_DM(df['High'], df['Low'], timeperiod=14)\n",
        "df['MOM1'] = talib.MOM(df['Close'], timeperiod=1)\n",
        "df['MOM3'] = talib.MOM(df['Close'], timeperiod=3)\n",
        "df['MOM5'] = talib.MOM(df['Close'], timeperiod=5)\n",
        "df['MOM10'] = talib.MOM(df['Close'], timeperiod=10)\n",
        "df['PLUS_DI'] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['PLUS_DM'] = talib.PLUS_DM(df['High'], df['Low'], timeperiod=14)\n",
        "df['PPO'] = talib.PPO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
        "df['ROC'] = talib.ROC(df['Close'], timeperiod=10)\n",
        "df['ROCP'] = talib.ROCP(df['Close'], timeperiod=10)\n",
        "df['ROCR'] = talib.ROCR(df['Close'], timeperiod=10)\n",
        "df['ROCR100'] = talib.ROCR100(df['Close'], timeperiod=10)\n",
        "df['RSI5'] = talib.RSI(df['Close'], timeperiod=5)\n",
        "df['RSI10'] = talib.RSI(df['Close'], timeperiod=10)\n",
        "df['RSI14'] = talib.RSI(df['Close'], timeperiod=14)\n",
        "slowk, slowd = talib.STOCH(df['High'], df['Low'], df['Close'], fastk_period=5, slowk_period=3, slowd_period=3)\n",
        "df['SLOWK'] = slowk\n",
        "df['SLOWD'] = slowd\n",
        "fastk, fastd = talib.STOCHF(df['High'], df['Low'], df['Close'], fastk_period=5, fastd_period=3)\n",
        "df['FASTK'] = fastk\n",
        "df['FASTD'] = fastd\n",
        "df['TRIX'] = talib.TRIX(df['Close'], timeperiod=30)\n",
        "df['ULTOSC'] = talib.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
        "df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "\n",
        "# VOLATILITY INDICATORS\n",
        "\n",
        "# ATR, NATR AND TRANGE\n",
        "\n",
        "df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['NATR'] = talib.NATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
        "df['TRANGE'] = talib.TRANGE(df['High'], df['Low'], df['Close'])\n",
        "\n",
        "# PATTERN RECOGNITION\n",
        "\n",
        "for indicator in pattern_recognition:\n",
        "    result = getattr(talib, indicator)(df.Open, df.High, df.Low, df.Close)\n",
        "    df[indicator] = result\n",
        "\n",
        "# CYCLE INDICATORS\n",
        "\n",
        "# HT DCPERIOD, HT DCPHASE and TRENDMODE\n",
        "\n",
        "df['HT DCPERIOD'] = talib.HT_DCPERIOD(df['Close'])\n",
        "df['HT DCPHASE'] = talib.HT_DCPHASE(df['Close'])\n",
        "df['TRENDMODE'] = talib.HT_TRENDMODE(df['Close'])\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "#feature dimension reduction\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "pca = PCA(n_components = 2)\n",
        "pca.fit(df[all_indicators])\n",
        "df2 = pca.transform(df[all_indicators])\n",
        "df2 = pd.DataFrame(df2, columns =['A', 'B', 'C'])\n",
        "all_indicators = ['A', 'B', 'C']\n",
        "df = pd.concat([df, df2], axis=1)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "#PNL code\n",
        "def pnl(df):\n",
        "    pos = 0\n",
        "\n",
        "    profit = 0\n",
        "    bt = 100\n",
        "    for index, row in df.iterrows():\n",
        "        if pos < 1 and df.Signal[index] == 1:\n",
        "            pos+=1\n",
        "            bt /= df.Close[index]\n",
        "        elif pos > -1 and df.Signal[index] == -1:\n",
        "            pos -=1\n",
        "            bt *= df.Close[index]\n",
        "        if pos == 0:\n",
        "            profit += bt - 100\n",
        "            bt = 100\n",
        "    return profit\n",
        "\n",
        "profit_percentage = []\n",
        "\n",
        "#I am only training with indices for now, it's training on roughly 8 month's data on predict next 2 month's\n",
        "#I'll learn how to parse datetime to do the above\n",
        "window = 150000\n",
        "for i in range(0, df.shape[0], int(0.2*window)):\n",
        "    train_df, test_df = df.iloc[i:i+1+int(0.8*window)], df.iloc[i+int(0.8*window):i+1+window]\n",
        "    X_train = train_df[all_indicators+['Close']].iloc[:-1]\n",
        "    fac = X_train.Close.pct_change().max()\n",
        "    y_train = np.where(train_df.Close.shift(-1).pct_change() > 0.01*fac, 1, np.where(train_df.Close.shift(-1).pct_change() < -0.01*fac, -1, 0))[:-1]\n",
        "    X_test = test_df[all_indicators+['Close']].iloc[:-1]\n",
        "    y_test = np.where(test_df.Close.shift(-1).pct_change() > 0.01*fac, 1, np.where(test_df.Close.shift(-1).pct_change() < -0.01*fac, -1, 0))[:-1]\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\")  # You can try RandomForestClassifier as well\n",
        "    #model = svm.SVC(C=10, kernel='linear')\n",
        "    model.fit(X_train, y_train)\n",
        "    try:\n",
        "      predictions = model.predict(X_test)\n",
        "      X_test['Signal'] = predictions\n",
        "      accuracy = accuracy_score(y_test, predictions)\n",
        "      #print(f'Accuracy: {accuracy}')\n",
        "      #print('PNL: ', pnl(X_test))\n",
        "      profit_percentage.append(pnl(X_test))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "print(sum(profit_percentage))"
      ]
    }
  ]
}